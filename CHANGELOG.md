# Changelog

### RoBERTa delta=0.005
folds [(0, 0.7099, (1, 0.7079), (4, 0.7063), (3, 0.7042), (2, 0.6997)]
avg 0.7056

### RoBERTa delta=0.001
folds [(1, 0.7096), (0, 0.7081), (3, 0.7047), (2, 0.7033), (4, 0.7019)]
avg 0.7055

### RoBERTa delta=0.001, усреднение двух слоев
[(1, 0.7101), (0, 0.7095), (3, 0.7076), (4, 0.7062), (2, 0.7013)]
avg 0.7069

### RoBERTa delta=0.001, усреднение 7 слоев
[(1, 0.7125), (4, 0.7082), (0, 0.7079), (2, 0.7042), (3, 0.7010)]
avg 0.70676

### RoBERTa delta=0.001, усреднение 7 слоев, seed=14, правильные token_id для sentiment
[(0, 0.7107), (4, 0.7099), (2, 0.7085), (1, 0.7047), (3, 0.7036)]
avg 0.70748

-----------------------------------------------------------------
### roBERTa multi-sample dropout 4 0.1 
[(0, 0.7108), (2, 0.7096), (4, 0.7088), (1, 0.7054), (3, 0.6999)]
avg 0.70696

### roBERTa multi-sample dropout 8 0.1
[(4, 0.7122), (0, 0.7096), (2, 0.7069), (1, 0.7041), (3, 0.7033)]
avg 0.70722

### roBERTa multi-sample dropout 2 0.1
[(0, 0.7107), (4, 0.7098), (2, 0.7093), (1, 0.7025), (3, 0.7018)]
avg 0.70680

### roBERTa multi-sample dropout 4 0.4 
[(0, 0.7126), (2, 0.7077), (1, 0.707), (3, 0.7048), (4, 0.7021)]
avg 0.70684 
----------------------------------------------------------------

### roBERTa dropout 1 0.2 
[(4, 0.7097), (0, 0.7087), (1, 0.7072), (2, 0.7071), (3, 0.7028)]
avg 0.70710

### roBERTa multi-sample dropout 1 0.4 (**)
[(2, 0.7095), (0, 0.7083), (3, 0.708), (1, 0.7074), (4, 0.7065)]
avg 0.70796
time 119m

### roBERTa multi-sample dropout 4 0.4  (*)
[(2, 0.7092), (4, 0.7085), (0, 0.7079), (1, 0.7069), (3, 0.7058)]
avg 0.70764
быстрее сходится, можно попробовать сделать 4 эпохи

### roBERTa multi-sample dropout 8 0.4 
[(2, 0.709), (4, 0.7088), (0, 0.7069), (3, 0.7049), (1, 0.7048)]
avg 0.70687

### roBERTa multi-sample dropout 4 0.4 + lin + gelu
[(1, 0.7108), (4, 0.7106), (0, 0.7103), (2, 0.7083), (3, 0.7037)]
avg 0.70873

### roBERTa multi-sample dropout 4 0.4 + lin + gelu 4 epoch
[(1, 0.7114), (4, 0.7106), (0, 0.7103), (2, 0.7085), (3, 0.704)]
avg 0.70895
time 105m

### roBERTa multi-sample dropout 4 0.4 + lin + gelu 4 epoch 2 head
[(4, 0.7108), (1, 0.7107), (2, 0.7103), (0, 0.7092), (3, 0.704)]
avg 0.70900

### roBERTa multi-sample dropout 4 0.4 + lin + gelu 4 epoch 2 head (l0 общий)
[(4, 0.7115), (0, 0.7097), (2, 0.7081), (1, 0.7045), (3, 0.6991)]


### (v24) roBERTa multi-sample dropout 4 0.4 + lin + gelu 5 epoch
[(1, 0.7108), (4, 0.7106), (0, 0.7103), (2, 0.7083), (3, 0.7037)]
avg 0.70873
time 116m
public 0.712

### roBERTa multi-sample dropout 1 0.1 + lin + gelu 5 epoch 2 head
[(4, 0.7117), (2, 0.7102), (0, 0.7057), (3, 0.7051), (1, 0.7034)]
avg 0.70723

### roBERTa 2 слоя multi-sample dropout 4 0.4 + lin + gelu 5 epoch
[(0, 0.7101), (4, 0.7086), (2, 0.7057), (1, 0.7038), (3, 0.7023)]
avg 0.70609

### (v25) roBERTa 2 слоя (cat -1) multi-sample dropout 4 0.4 + lin + gelu 5 epoch, xavier_normal
[(0, 0.7127), (4, 0.7123), (1, 0.7083), (2, 0.7074), (3, 0.7045)]
avg 0.70904
public 0.712

### (v27) v25 + усреднение веротностей
[(0, 0.7127), (4, 0.7123), (1, 0.7083), (2, 0.7074), (3, 0.7045)]
avg 0.70904
public 0.713